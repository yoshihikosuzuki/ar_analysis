{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"data/\"\n",
    "lc_fname = \"listed_company\"\n",
    "#pr_fname = \"test.csv\"\n",
    "#pr_fname = \"pressrelease_all.csv\"\n",
    "matching_fname = \"matchings.new\"\n",
    "kabuka_fname = \"kabuka_tse1\"\n",
    "market_fname = \"market_tse1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lc_code = {}\n",
    "with open(data_dir + lc_fname, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split('\\t')\n",
    "        lc_code[data[0]] = data[2]\n",
    "        \n",
    "#print(lc_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matching = {}\n",
    "with open(matching_fname, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split('\\t')\n",
    "        comp = data[3].strip().split(' ')\n",
    "        comp_list = []\n",
    "        comp_code_list = []\n",
    "        for x in comp:\n",
    "            if x in lc_code:\n",
    "                comp_list.append(x)\n",
    "                comp_code_list.append(lc_code[x])\n",
    "        if len(comp_list) > 0:\n",
    "            matching[data[0]] = (data[1], data[2], comp_code_list, comp_list)\n",
    "#print(matching)\n",
    "# {articleid : (prtype, date, [code], [name])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NIKPRLRSP037981_06012003', 'NIKPRLRSP037996_06012003', 'NIKPRLRSP038000_06012003']\n",
      "[('06: Order', '20030105', ['8226'], ['理経']), ('99_Others', '20030106', ['8379'], ['広島銀行']), ('01: Product', '20030106', ['4829'], ['日本エンタープライズ'])]\n"
     ]
    }
   ],
   "source": [
    "print(list(matching.keys())[:3])\n",
    "print(list(matching.values())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TOPIXデータの読み込み\n",
    "\n",
    "topix = []\n",
    "with open(data_dir + market_fname, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split(',')\n",
    "        #comp_code = data[0]\n",
    "        for x in data[1:]:\n",
    "            date, value = x.split(':')\n",
    "            topix.append((date, value))\n",
    "            \n",
    "import pandas as pd\n",
    "dates = [x[0] for x in topix]\n",
    "values = [float(x[1]) for x in topix]\n",
    "\n",
    "market = pd.DataFrame({\"value\": values})\n",
    "market.index = pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 株価データの読み込み、欠損値がある企業はどうする？\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "kabuka = defaultdict(list)\n",
    "with open(data_dir + kabuka_fname, 'r') as f:\n",
    "    for line in f:\n",
    "        data = line.strip().split(',')\n",
    "        comp_code = data[0]\n",
    "        for x in data[1:]:\n",
    "            date, value = x.split(':')\n",
    "            kabuka[comp_code].append((date, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_interval(data, market, date):   # DataFrame, DataFrame, datetime\n",
    "    er_start= -246 - 1\n",
    "    er_end = -30 \n",
    "    #ar_start = -1 - 1\n",
    "    #ar_end = 1\n",
    "    \n",
    "    data_val = data[data.columns[0]]\n",
    "    market_val = market[market.columns[0]]\n",
    "    \n",
    "    ## 指定された日付がデータの範囲に収まっているか判定\n",
    "    max_date = max(data.index)\n",
    "    while (max_date not in data_val or data_val[max_date] == 0.):\n",
    "        max_date = max_date - pd.offsets.Day(1)\n",
    "    min_date = min(data.index)\n",
    "    while (min_date not in data_val or data_val[min_date] == 0.):\n",
    "        min_date = min_date + pd.offsets.Day(1)\n",
    "    if date < min_date or date > max_date:\n",
    "        return   # OutOfIndex\n",
    "    \n",
    "    ## 与えられたdate以降の日付で、株価データが存在するような最も近い日付を求める\n",
    "    while (date not in data_val or data_val[date] == 0.):\n",
    "        date = date + pd.offsets.Day(1) \n",
    "        if date > max_date:\n",
    "            return \n",
    "    origin = date\n",
    "    #print(\"Origin:\", date)\n",
    "    \n",
    "    ## 計算に使う範囲の(有効な)株価データを抽出 -> リファクタリング: 先に株価0のエントリーを除去してから連続的に区間を抽出するだけで良い\n",
    "    er_data = []\n",
    "    er_market = []\n",
    "    ar_data = []\n",
    "    ar_market = []\n",
    "    \n",
    "    count = 0\n",
    "    date = origin\n",
    "    while (er_end < count):\n",
    "        date = date - pd.offsets.Day(1)\n",
    "        if date < min_date:\n",
    "            return\n",
    "        if date in data_val and data_val[date] >  0.:\n",
    "            count -= 1\n",
    "    #print(\"Er_end:\", date)\n",
    "    er_data.append(data_val[date])\n",
    "    er_market.append(market_val[date])\n",
    "    while (er_start < count):\n",
    "        date = date - pd.offsets.Day(1)\n",
    "        if date < min_date:\n",
    "            return\n",
    "        if date  in data_val and data_val[date] >  0.:\n",
    "            er_data.append(data_val[date])\n",
    "            er_market.append(market_val[date])\n",
    "            count -= 1\n",
    "    #print(\"Er_start:\", date)\n",
    "    er_data.reverse()\n",
    "    er_market.reverse()\n",
    "    #print(er_data, er_market)\n",
    "    \n",
    "    date = origin - pd.offsets.Day(1)\n",
    "    while (date not in data_val or data_val[date] == 0.):\n",
    "        date = date - pd.offsets.Day(1) \n",
    "        if date < min_date:\n",
    "            return\n",
    "    ar_data.append(data_val[date])    # at -1\n",
    "    ar_market.append(market_val[date])\n",
    "    date = date - pd.offsets.Day(1)\n",
    "    while (date not in data_val or data_val[date] == 0.):\n",
    "        date = date - pd.offsets.Day(1) \n",
    "        if date < min_date:\n",
    "            return\n",
    "    ar_data.append(data_val[date])   # at -2\n",
    "    ar_market.append(market_val[date])\n",
    "    ar_data.reverse()\n",
    "    ar_market.reverse()\n",
    "    \n",
    "    ar_data.append(data_val[origin])   # at 0\n",
    "    ar_market.append(market_val[origin])\n",
    "    date = origin + pd.offsets.Day(1)\n",
    "    while (date not in data_val or data_val[date] == 0.):\n",
    "        date = date + pd.offsets.Day(1) \n",
    "        if date > max_date:\n",
    "            return\n",
    "    ar_data.append(data_val[date])   # at +1\n",
    "    ar_market.append(market_val[date])\n",
    "    #print(ar_data, ar_market)\n",
    "    \n",
    "    import numpy as np\n",
    "    return (np.array(er_data), np.array(er_market), np.array(ar_data), np.array(ar_market))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# data: arを計算したい企業の株価時系列データ\n",
    "# market: 株価指数時系列データ\n",
    "# start_period [end_period]: 期待値の計算に使う期間の開始[終了]日時\n",
    "# start_window [end_window]: arを計算したい期間の開始[終了]日時\n",
    "\n",
    "# 欠損値はこれに渡す前に整形する？dataで0になっているところをdata, market両方から除去とか\n",
    "# その場合、*_periodの値も調整してから渡す必要がある\n",
    "\n",
    "def market_return(er_data, er_market, ar_data, ar_market):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from scipy import stats\n",
    "    from datetime import datetime\n",
    "    \n",
    "    #print(\"DATA:\", ar_data)\n",
    "    #print(\"MARKET:\", ar_market)\n",
    "        \n",
    "    def calculate_returns(d):   # np.array of stock values\n",
    "        dr = np.zeros(shape=d.shape)\n",
    "        dr[1:] = d[1:] / d[0:-1]# - 1   # why -1?\n",
    "        return dr[1:]\n",
    "    \n",
    "    # 1. Linear Regression: On the estimation_period\n",
    "    er_data = calculate_returns(er_data)\n",
    "    er_market = calculate_returns(er_market)\n",
    "    ar_data = calculate_returns(ar_data)\n",
    "    ar_market = calculate_returns(ar_market)\n",
    "    \n",
    "    #print(\"\")\n",
    "    #print(\"RETURN(DATA):\", ar_data)\n",
    "    #print(\"RETURN(MARKET):\", ar_market)\n",
    "    \n",
    "    #c_name = dr_data.columns[0]\n",
    "    #x =  dr_market[c_name][start_period:end_period]\n",
    "    #y = dr_data[c_name][start_period:end_period]\n",
    "    slope, intercept, r_value, p_value, std_error = stats.linregress(er_market, er_data)\n",
    "    er_reg = lambda x: x * slope + intercept\n",
    "    \n",
    "    #print(\"\")\n",
    "    #print(\"REG(DATA):\", er_data)\n",
    "    #print(\"REG(MARKET):\", er_market)\n",
    "    #print(\"REG: DATA = \" + str(slope) + \"MARKET + \" + str(intercept))\n",
    "    #print(\"\")\n",
    "\n",
    "    # 2. Analysis on the event window\n",
    "    # Expexted Return:\n",
    "    er = er_reg(ar_market)\n",
    "    #er.name = 'Expected return'\n",
    "    # Abnormal return: Return of the data - expected return\n",
    "    ar = ar_data - er\n",
    "    #ar.name = 'Abnormal return'\n",
    "    # Cumulative abnormal return\n",
    "    car = ar.cumsum()\n",
    "    #car.name = 'Cum abnormal return'\n",
    "    \n",
    "    #print(\"ER:\", er)\n",
    "    #print(\"AR:\", ar)\n",
    "    #print(\"CAR:\", car)\n",
    "    return car[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_kabuka(code):\n",
    "    import pandas as pd\n",
    "    dates = [x[0] for x in kabuka[code]]\n",
    "    values = [float(x[1]) for x in kabuka[code]]\n",
    "\n",
    "    data = pd.DataFrame({\"value\": values})\n",
    "    data.index = pd.to_datetime(dates)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "car = {}\n",
    "for articleid, data in matching.items():\n",
    "    #print(articleid)\n",
    "    #count += 1\n",
    "    #if count > 10:\n",
    "    #    break\n",
    "    #print(data)\n",
    "    prtype, date, codes, names = data\n",
    "    #print(date)\n",
    "    for code in codes:\n",
    "        #print(code)\n",
    "        if code not in kabuka:\n",
    "            #print(\"no code\")\n",
    "            continue\n",
    "        kabuka_data = load_kabuka(code)\n",
    "        #print(kabuka_data)\n",
    "        ret = determine_interval(kabuka_data, market, pd.to_datetime(date))\n",
    "        if ret == None:\n",
    "            #print(\"no kabuka\")\n",
    "            continue\n",
    "        ed, em, ad, am = ret\n",
    "        car[(articleid, prtype, code)] = market_return(ed, em, ad, am)   # エイリアスはここで縮約されるか\n",
    "        #print(car[(articleid, code)])\n",
    "#print(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"car.new\", 'w') as f:\n",
    "    for key, v in car.items():\n",
    "        articleid, prtype, code = key\n",
    "        f.write('\\t'.join([articleid, prtype, code, str(v)]))\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47301"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 並列化版\n",
    "def calculate_car(matching_data):\n",
    "    articleid, data = matching_data\n",
    "    prtype, date, codes, names = data\n",
    "    #print(date)\n",
    "    for code in codes:\n",
    "        #print(code)\n",
    "        if code not in kabuka:\n",
    "            #print(\"no code\")\n",
    "            continue\n",
    "        kabuka_data = load_kabuka(code)\n",
    "        #print(kabuka_data)\n",
    "        ret = determine_interval(kabuka_data, market, pd.to_datetime(date))\n",
    "        if ret == None:\n",
    "            #print(\"no kabuka\")\n",
    "            continue\n",
    "        ed, em, ad, am = ret\n",
    "        #car[(articleid, prtype, code)] = market_return(ed, em, ad, am)   # エイリアスはここで縮約されるか\n",
    "        return (articleid, prtype, code, market_return(ed, em, ad, am))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "exe_pool = Pool(16)\n",
    "car_p = {}\n",
    "for ret in exe_pool.imap(calculate_car, matching.items()):\n",
    "    car_p[(ret[0], ret[1], ret[2])] = ret[3]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
